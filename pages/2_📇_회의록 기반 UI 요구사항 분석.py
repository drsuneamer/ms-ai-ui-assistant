from dotenv import load_dotenv
import os
import streamlit as st
from langchain_openai import AzureChatOpenAI
from langchain.schema import HumanMessage, SystemMessage
import json


# ì‚¬ìš©ìì˜ íšŒì˜ë¡ì„ ë¶„ì„í•˜ì—¬ UI/UX ê°œì„  ìš”êµ¬ì‚¬í•­ì„ ë„ì¶œí•˜ëŠ” ê¸°ëŠ¥ ì œê³µ í˜ì´ì§€
# txt, md íŒŒì¼ ì—…ë¡œë“œ ë˜ëŠ” ì§ì ‘ ì…ë ¥ ê°€ëŠ¥
# íšŒì˜ë¡ ë‚´ìš©ì€ LangChain LLMì„ í†µí•´ ë¶„ì„ë˜ë©°, 
# UI/UX ê´€ë ¨ ìš”êµ¬ì‚¬í•­ê³¼ ì‚¬ìš©ì í”¼ë“œë°±ì„ JSON/MARKDOWN í˜•ì‹ìœ¼ë¡œ ì¶œë ¥


# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
llm_name = os.getenv("AZURE_OPENAI_LLM_MINI")

# LangChain Azure OpenAI í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
@st.cache_resource
def init_langchain_client():
    try:
        llm = AzureChatOpenAI(
            azure_deployment=llm_name,
            api_version=os.getenv("OPENAI_API_VERSION"),
            azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT"),
            api_key=os.getenv("OPENAI_API_KEY"),
            temperature=0.0  # ì°½ì˜ì„± ìµœì†Œí™”
        )
        return llm
    except Exception as e:
        st.error(f"LangChain Azure OpenAI ì—°ê²° ì‹¤íŒ¨: {str(e)}")
        return None

# ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì •ì˜
SYSTEM_PROMPT = """
ë‹¹ì‹ ì€ íšŒì˜ë¡ì„ ë¶„ì„í•˜ì—¬ UI/UX ê°œì„  ìš”êµ¬ì‚¬í•­ì„ íŒŒì•…í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

**ë¶„ì„ ëª©í‘œ:**
1. íšŒì˜ë¡ì—ì„œ UI/UX ê´€ë ¨ ê°œì„ ì‚¬í•­ì„ ì¶”ì¶œ
2. ì‚¬ìš©ì í”¼ë“œë°±ê³¼ ê°œë°œ ìš”êµ¬ì‚¬í•­ êµ¬ë¶„
3. êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ê°œì„ ì•ˆ ë„ì¶œ

**ì¶œë ¥ í˜•ì‹ (JSON):**
{
  "ui_requirements": [
    {
      "category": "ë²„íŠ¼/ì¸í„°í˜ì´ìŠ¤/ë ˆì´ì•„ì›ƒ/ìƒ‰ìƒ/í…ìŠ¤íŠ¸ ì¤‘ í•˜ë‚˜",
      "current_issue": "í˜„ì¬ ë¬¸ì œì ",
      "improvement_request": "ê°œì„  ìš”êµ¬ì‚¬í•­",
      "priority": "high/medium/low",
      "technical_detail": "êµ¬ì²´ì ì¸ êµ¬í˜„ ë°©í–¥"
    }
  ],
  "user_feedback": [
    {
      "feedback": "ì‚¬ìš©ìê°€ ì œê¸°í•œ êµ¬ì²´ì  í”¼ë“œë°±",
      "pain_point": "ì‚¬ìš©ì ë¶ˆí¸ì‚¬í•­",
      "suggested_solution": "ì œì•ˆëœ í•´ê²°ë°©ì•ˆ"
    }
  ],
  "summary": {
    "total_requirements": "ì´ ìš”êµ¬ì‚¬í•­ ìˆ˜",
    "high_priority_count": "ê³ ìš°ì„ ìˆœìœ„ í•­ëª© ìˆ˜",
    "main_focus_areas": ["ì£¼ìš” ê°œì„  ì˜ì—­ë“¤"]
  }
}

**ë¶„ì„ ì‹œ ê³ ë ¤ì‚¬í•­:**
- ëª…í™•í•˜ì§€ ì•Šì€ ìš”êµ¬ì‚¬í•­ì€ í•©ë¦¬ì ìœ¼ë¡œ í•´ì„
- ì‚¬ìš©ì ê²½í—˜ ê´€ì ì—ì„œ ìš°ì„ ìˆœìœ„ ì„¤ì •
- ê°œë°œ ë³µì¡ë„ì™€ ì‚¬ìš©ì ì„íŒ©íŠ¸ ê³ ë ¤
"""

def analyze_meeting_content(llm, content):
    """íšŒì˜ë¡ ë‚´ìš©ì„ LangChain LLMìœ¼ë¡œ ë¶„ì„"""
    try:
        # LangChain ë©”ì‹œì§€ êµ¬ì„±
        messages = [
            SystemMessage(content=SYSTEM_PROMPT),
            HumanMessage(content=f"ë‹¤ìŒ íšŒì˜ë¡ì„ ë¶„ì„í•´ì£¼ì„¸ìš”:\n\n{content}")
        ]
        
        # LLM í˜¸ì¶œ
        response = llm.invoke(messages)
        
        # JSON íŒŒì‹± ì‹œë„
        try:
            analysis_result = json.loads(response.content)
            return {"success": True, "data": analysis_result, "raw": response.content}
        except json.JSONDecodeError:
            # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ raw text ë°˜í™˜
            return {"success": True, "data": None, "raw": response.content}
            
    except Exception as e:
        return {"success": False, "error": str(e)}

def display_analysis_results(result):
    """ë¶„ì„ ê²°ê³¼ í‘œì‹œ"""
    if result["data"]:  # JSON íŒŒì‹± ì„±ê³µ
        data = result["data"]
        
        # ìš”ì•½ ì •ë³´
        st.subheader("ğŸ“Š ë¶„ì„ ìš”ì•½")
        if "summary" in data:
            summary = data["summary"]
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("ì´ ìš”êµ¬ì‚¬í•­", summary.get("total_requirements", "N/A"))
            with col2:
                st.metric("ê³ ìš°ì„ ìˆœìœ„", summary.get("high_priority_count", "N/A"))
            with col3:
                focus_areas = summary.get("main_focus_areas", [])
                st.metric("ì£¼ìš” ì˜ì—­", len(focus_areas) if focus_areas else "N/A")
        
        # UI ìš”êµ¬ì‚¬í•­
        if "ui_requirements" in data and data["ui_requirements"]:
            st.subheader("ğŸ¯ UI ê°œì„  ìš”êµ¬ì‚¬í•­")
            
            for i, req in enumerate(data["ui_requirements"]):
                with st.expander(f"{req.get('category', 'UI')} - {req.get('current_issue', 'Issue')[:50]}..."):
                    st.write(f"**ì¹´í…Œê³ ë¦¬:** {req.get('category', 'N/A')}")
                    st.write(f"**í˜„ì¬ ë¬¸ì œ:** {req.get('current_issue', 'N/A')}")
                    st.write(f"**ê°œì„  ìš”ì²­:** {req.get('improvement_request', 'N/A')}")
                    st.write(f"**ìš°ì„ ìˆœìœ„:** {req.get('priority', 'N/A')}")
                    st.write(f"**êµ¬í˜„ ë°©í–¥:** {req.get('technical_detail', 'N/A')}")
        
        # ì‚¬ìš©ì í”¼ë“œë°±
        if "user_feedback" in data and data["user_feedback"]:
            st.subheader("ğŸ‘¥ ì‚¬ìš©ì í”¼ë“œë°±")
            
            for i, feedback in enumerate(data["user_feedback"]):
                with st.container():
                    st.write(f"**í”¼ë“œë°± {i+1}:**")
                    st.info(feedback.get('feedback', 'N/A'))
                    st.write(f"**ë¶ˆí¸ì‚¬í•­:** {feedback.get('pain_point', 'N/A')}")
                    st.write(f"**ì œì•ˆ í•´ê²°ì±…:** {feedback.get('suggested_solution', 'N/A')}")
                    st.divider()
    
    else:  # JSON íŒŒì‹± ì‹¤íŒ¨, raw text í‘œì‹œ
        st.subheader("ğŸ“ ë¶„ì„ ê²°ê³¼")
        st.markdown(result["raw"])

def result_to_markdown(data):
    """ë¶„ì„ ê²°ê³¼(JSON)ë¥¼ Markdown í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    md = "# ğŸ“‹ íšŒì˜ë¡ UI ìš”êµ¬ì‚¬í•­ ë¶„ì„ ê²°ê³¼\n\n"
    if "summary" in data:
        md += "## ğŸ“Š ìš”ì•½\n"
        summary = data["summary"]
        md += f"- **ì´ ìš”êµ¬ì‚¬í•­:** {summary.get('total_requirements', 'N/A')}\n"
        md += f"- **ê³ ìš°ì„ ìˆœìœ„:** {summary.get('high_priority_count', 'N/A')}\n"
        focus_areas = summary.get("main_focus_areas", [])
        md += f"- **ì£¼ìš” ì˜ì—­:** {', '.join(focus_areas) if focus_areas else 'N/A'}\n\n"
    if "ui_requirements" in data and data["ui_requirements"]:
        md += "## ğŸ¯ UI ê°œì„  ìš”êµ¬ì‚¬í•­\n"
        for req in data["ui_requirements"]:
            md += f"- **ì¹´í…Œê³ ë¦¬:** {req.get('category', 'N/A')}\n"
            md += f"  - **í˜„ì¬ ë¬¸ì œ:** {req.get('current_issue', 'N/A')}\n"
            md += f"  - **ê°œì„  ìš”ì²­:** {req.get('improvement_request', 'N/A')}\n"
            md += f"  - **ìš°ì„ ìˆœìœ„:** {req.get('priority', 'N/A')}\n"
            md += f"  - **êµ¬í˜„ ë°©í–¥:** {req.get('technical_detail', 'N/A')}\n\n"
    if "user_feedback" in data and data["user_feedback"]:
        md += "## ğŸ‘¥ ì‚¬ìš©ì í”¼ë“œë°±\n"
        for feedback in data["user_feedback"]:
            md += f"- **í”¼ë“œë°±:** {feedback.get('feedback', 'N/A')}\n"
            md += f"  - **ë¶ˆí¸ì‚¬í•­:** {feedback.get('pain_point', 'N/A')}\n"
            md += f"  - **ì œì•ˆ í•´ê²°ì±…:** {feedback.get('suggested_solution', 'N/A')}\n\n"
    return md

# ë©”ì¸ ì•±
def main():
    st.set_page_config(
        page_title="íšŒì˜ë¡ ìš”êµ¬ì‚¬í•­ ë¶„ì„ê¸°",
        page_icon="ğŸ“‹",
        layout="wide"
    )
    
    st.title("ğŸ“‹ íšŒì˜ë¡ UI ìš”êµ¬ì‚¬í•­ ë¶„ì„ê¸°")
    st.markdown("íšŒì˜ ì „ë¬¸ì„ ì—…ë¡œë“œí•˜ë©´ AIê°€ UI/UX ê°œì„  ìš”êµ¬ì‚¬í•­ì„ ë¶„ì„í•´ë“œë¦½ë‹ˆë‹¤.")
    
    # LangChain í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    llm = init_langchain_client()
    if not llm:
        st.error("âŒ LangChain Azure OpenAI ì—°ê²°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. í™˜ê²½ë³€ìˆ˜ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        st.code("""
        í•„ìš”í•œ í™˜ê²½ë³€ìˆ˜:
        - AZURE_OPENAI_API_KEY
        - AZURE_OPENAI_ENDPOINT  
        - AZURE_OPENAI_API_VERSION
        - AZURE_OPENAI_LLM_MINI
        """)
        return
    
    # ì‚¬ì´ë“œë°” ì„¤ì •
    with st.sidebar:
        st.subheader("âš™ï¸ ë¶„ì„ ì„¤ì •")
        
        # í”„ë¡¬í”„íŠ¸ ì»¤ìŠ¤í„°ë§ˆì´ì§•
        with st.expander("ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìˆ˜ì •"):
            custom_prompt = st.text_area(
                "ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸:",
                value=SYSTEM_PROMPT,
                height=200
            )
        
        # ë¶„ì„ ì˜µì…˜
        analysis_focus = st.selectbox(
            "ë¶„ì„ ì§‘ì¤‘ ì˜ì—­:",
            ["ì „ì²´ ë¶„ì„", "UI ìš”êµ¬ì‚¬í•­ ì¤‘ì‹¬", "ì‚¬ìš©ì í”¼ë“œë°± ì¤‘ì‹¬", "ê¸°ìˆ ì  êµ¬í˜„ ì¤‘ì‹¬"]
        )
    
    # ë©”ì¸ ì»¨í…ì¸ 
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.subheader("ğŸ“„ íšŒì˜ë¡ ì—…ë¡œë“œ")
        
        # íŒŒì¼ ì—…ë¡œë“œ
        uploaded_file = st.file_uploader("íšŒì˜ ì „ë¬¸ì„ ì˜¬ë ¤ë³´ì„¸ìš”", type=["txt", "md"])
        
        content = ""
        if uploaded_file is not None:
            content = uploaded_file.read().decode("utf-8")
            st.text_area("íŒŒì¼ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°:", content, height=300, disabled=True)
        else:
            st.markdown("ë˜ëŠ” ì§ì ‘ ì…ë ¥:")
            content = st.text_area("íšŒì˜ë¡ ë‚´ìš©ì„ ì§ì ‘ ì…ë ¥í•˜ì„¸ìš”:", height=300, 
                                 placeholder="íšŒì˜ ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.", key="meeting_input")
            
        # ì…ë ¥ ì™„ë£Œ ë²„íŠ¼
        if st.button("ğŸ“ ì…ë ¥ ì™„ë£Œ", 
                    type="secondary", 
                    use_container_width=True):
            st.session_state["input_ready"] = True
            st.rerun()
    
    with col2:
        st.subheader("ğŸ¤– AI ë¶„ì„ ê²°ê³¼")
        
        # ì…ë ¥ì´ ì¤€ë¹„ë˜ì—ˆê±°ë‚˜ íŒŒì¼ì´ ì—…ë¡œë“œëœ ê²½ìš°
        is_ready = (uploaded_file is not None) or st.session_state.get("input_ready", False)
        
        # ë¶„ì„ ê²°ê³¼ë¥¼ ì„¸ì…˜ ìƒíƒœì— ì €ì¥
        if is_ready and content.strip():
            if st.button("ğŸš€ ìš”êµ¬ì‚¬í•­ ë¶„ì„ ì‹œì‘", type="primary", use_container_width=True):
                with st.spinner("ğŸ¤– AIê°€ íšŒì˜ë¡ì„ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
                    system_prompt = custom_prompt if 'custom_prompt' in locals() else SYSTEM_PROMPT
                    result = analyze_meeting_content(llm, content)
                    st.session_state["analysis_result"] = result  # ì„¸ì…˜ ìƒíƒœì— ì €ì¥

        # ì„¸ì…˜ ìƒíƒœì— ê²°ê³¼ê°€ ìˆìœ¼ë©´ í‘œì‹œ ë° ë‹¤ìš´ë¡œë“œ
        if "analysis_result" in st.session_state:
            result = st.session_state["analysis_result"]
            if result["success"]:
                st.success("âœ… ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
                display_analysis_results(result)
                st.download_button(
                    label="ğŸ“¥ ë¶„ì„ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ (JSON)",
                    data=result["raw"],
                    file_name="meeting_analysis_result.json",
                    mime="application/json"
                )
                if result["data"]:
                    md_data = result_to_markdown(result["data"])
                    st.download_button(
                        label="ğŸ“¥ ë¶„ì„ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ (Markdown)",
                        data=md_data,
                        file_name="meeting_analysis_result.md",
                        mime="text/markdown"
                    )
            else:
                st.error(f"âŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {result['error']}")
        else:
            st.info("ğŸ‘† íšŒì˜ë¡ì„ ì—…ë¡œë“œí•˜ê±°ë‚˜ ì§ì ‘ ì…ë ¥ í›„ 'ì…ë ¥ ì™„ë£Œ' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")

if __name__ == "__main__":
    main()